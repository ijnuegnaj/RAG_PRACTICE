{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ijnuegnaj/RAG_PRACTICE/blob/practice1/1_LangChain_%E1%84%8F%E1%85%A5%E1%86%B7%E1%84%91%E1%85%A9%E1%84%82%E1%85%A5%E1%86%AB%E1%84%90%E1%85%B3_%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%E1%84%80%E1%85%AA_%E1%84%91%E1%85%A1%E1%84%89%E1%85%A5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 모델과 파서   \n",
        "\n",
        "- 모델 : gpt-4o, ..< 다양한 버전의 모델에 어떻게 접근, 대화를 어떻게 세팅할 수 있는지   \n",
        "- 파서 : 내가 원하는 포맷으로 api의 답변을 컨트롤 할 수 있는 모듈"
      ],
      "metadata": {
        "id": "5XOzxM-h2gTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-mlZMHj2HHk",
        "outputId": "d48cc141-9ce3-4923-cf36-f53a42751686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#openai 구버전(0.28)\n",
        "#python-dotenv : 파이썬 환경설정\n",
        "# -q(quiet) 조용하게 파이썬 패키지 설치\n",
        "!pip install -q python-dotenv openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "#api 사용을 위한 '키' 연결\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('ssu')"
      ],
      "metadata": {
        "id": "rGS4K6pY3Upn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. OpenAI와 API를 사용한 통신"
      ],
      "metadata": {
        "id": "lYQ1f3P-68fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "#gpt-3.5-turbo => gpt의 통신가능한 구버전 모델\n",
        "llm_model = 'gpt-3.5-turbo'\n",
        "\n",
        "#통신에 필요한 3가지!\n",
        "#query = '질문', model= gpt 모델 세팅, prompt=응답의 정도 정하기\n",
        "def get_chat(prompt, query, model=llm_model):\n",
        "  #gpt에 직접 보내는 메시지는 리스트 형태로 전달\n",
        "  #각 딕셔너리마다 'role'과 'content'가 포함\n",
        "  messages = [\n",
        "      {'role':'system', 'content':prompt}, #gpt가 이렇게 해줬으면 좋겠다~ 라는 응답 태도 설정\n",
        "      {'role':'user', 'content':query} #사람이 웹에서 채팅 창에 치던 질문(query)를 코드로는 이렇게 전달.\n",
        "  ]\n",
        "\n",
        "  #답변할 gpt에게, 개인 카톡방을 개설\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0.5  #정답의 창의성 정도(0~1) 1에 가까울수록 창의성 증가\n",
        "  )\n",
        "  print(response)\n",
        "\n",
        "  return response.choices[0].message['content']"
      ],
      "metadata": {
        "id": "SVRx_V3M6BM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_chat('친절하고 상냥하게 답변해줘', 'LangChain을 쓰면 뭐가 좋아?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AmxeVOtRBPzr",
        "outputId": "e9f01cce-a301-4e02-c278-6025e86600e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-C1rumdBxVI79BnESgrNwOYDRvVJYI\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1754561612,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"LangChain\\uc740 \\ub2e4\\uad6d\\uc5b4 \\ubc88\\uc5ed \\ubc0f \\uc5b8\\uc5b4 \\uc11c\\ube44\\uc2a4\\uc5d0 \\ud2b9\\ud654\\ub41c \\uae30\\uc220\\uc744 \\uc81c\\uacf5\\ud558\\uc5ec \\uc5b8\\uc5b4 \\uac04 \\uc18c\\ud1b5\\uc744 \\uc6d0\\ud65c\\ud558\\uac8c \\ub3c4\\uc640\\uc90d\\ub2c8\\ub2e4. \\uc774\\ub97c \\ud1b5\\ud574 \\ub2e4\\uc74c\\uacfc \\uac19\\uc740 \\uc7a5\\uc810\\uc744 \\uc5bb\\uc744 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4:\\n\\n1. \\ube60\\ub978 \\ubc88\\uc5ed \\uc11c\\ube44\\uc2a4: LangChain\\uc744 \\uc0ac\\uc6a9\\ud558\\uba74 \\uc2e4\\uc2dc\\uac04\\uc73c\\ub85c \\ub2e4\\uad6d\\uc5b4 \\ubc88\\uc5ed\\uc774 \\uac00\\ub2a5\\ud558\\uc5ec \\uc18c\\ud1b5\\uc774 \\ube60\\ub974\\uace0 \\ud6a8\\uc728\\uc801\\uc73c\\ub85c \\uc774\\ub8e8\\uc5b4\\uc9d1\\ub2c8\\ub2e4.\\n\\n2. \\ub2e4\\uc591\\ud55c \\uc5b8\\uc5b4 \\uc9c0\\uc6d0: LangChain\\uc740 \\ub2e4\\uc591\\ud55c \\uc5b8\\uc5b4\\ub97c \\uc9c0\\uc6d0\\ud558\\uc5ec \\uc804 \\uc138\\uacc4 \\uc5b4\\ub514\\uc11c\\ub098 \\uc190\\uc27d\\uac8c \\uc0ac\\uc6a9\\ud560 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\n\\n3. \\uc815\\ud655\\ud55c \\ubc88\\uc5ed: LangChain\\uc740 \\uace0\\uae09 \\uc778\\uacf5\\uc9c0\\ub2a5 \\uae30\\uc220\\uc744 \\ud65c\\uc6a9\\ud558\\uc5ec \\uc815\\ud655\\ud55c \\ubc88\\uc5ed\\uc744 \\uc81c\\uacf5\\ud558\\uc5ec \\uc624\\uc5ed\\uc774\\ub098 \\uc624\\ud574\\ub97c \\ubc29\\uc9c0\\ud569\\ub2c8\\ub2e4.\\n\\n4. \\ube44\\uc6a9 \\uc808\\uac10: LangChain\\uc744 \\uc0ac\\uc6a9\\ud568\\uc73c\\ub85c\\uc368 \\ubc88\\uc5ed \\ube44\\uc6a9\\uc744 \\uc808\\uac10\\ud558\\uace0 \\ube44\\uc988\\ub2c8\\uc2a4\\ub098 \\uac1c\\uc778\\uc801\\uc778 \\uc18c\\ud1b5\\uc744 \\ud6a8\\uc728\\uc801\\uc73c\\ub85c \\uc774\\ub8f0 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\n\\n\\uc774\\ub7ec\\ud55c \\uc774\\uc720\\ub85c LangChain\\uc740 \\ub2e4\\uad6d\\uc5b4 \\uc18c\\ud1b5\\uc744 \\ud544\\uc694\\ub85c \\ud558\\ub294 \\ub2e4\\uc591\\ud55c \\uc0c1\\ud669\\uc5d0\\uc11c \\ub9e4\\uc6b0 \\uc720\\uc6a9\\ud558\\uac8c \\ud65c\\uc6a9\\ub420 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\",\n",
            "        \"refusal\": null,\n",
            "        \"annotations\": []\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 44,\n",
            "    \"completion_tokens\": 346,\n",
            "    \"total_tokens\": 390,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain은 다국어 번역 및 언어 서비스에 특화된 기술을 제공하여 언어 간 소통을 원활하게 도와줍니다. 이를 통해 다음과 같은 장점을 얻을 수 있습니다:\\n\\n1. 빠른 번역 서비스: LangChain을 사용하면 실시간으로 다국어 번역이 가능하여 소통이 빠르고 효율적으로 이루어집니다.\\n\\n2. 다양한 언어 지원: LangChain은 다양한 언어를 지원하여 전 세계 어디서나 손쉽게 사용할 수 있습니다.\\n\\n3. 정확한 번역: LangChain은 고급 인공지능 기술을 활용하여 정확한 번역을 제공하여 오역이나 오해를 방지합니다.\\n\\n4. 비용 절감: LangChain을 사용함으로써 번역 비용을 절감하고 비즈니스나 개인적인 소통을 효율적으로 이룰 수 있습니다.\\n\\n이러한 이유로 LangChain은 다국어 소통을 필요로 하는 다양한 상황에서 매우 유용하게 활용될 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LangChain 이용하기"
      ],
      "metadata": {
        "id": "tPxDs7ghCM2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#구버전의 langchain 라이브러리를 고정\n",
        "!pip install -q langchain==0.1.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "neMUAauVBYbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#랭체인의 다양한 모델 중에서 'OpenAI'랑 통신할 수 있게 하는 클래스\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "#채팅을 위한 프롬프트 > '프롬프트 템플릿'\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "p4mJJQUQCZyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPT와 카톡방을 만듦\n",
        "chat = ChatOpenAI(temperature=0.5, model=llm_model)\n",
        "\n",
        "\n",
        "\n",
        "customer_email = '''\n",
        "아니 어제 산 모니터가 안켜짐. 이게 맞음?\n",
        "반품하려고 했더니 고객센터도 전화를 안받네\n",
        "장사 접어라\n",
        "빡치게 만들지 말고;;\n",
        "'''\n",
        "\n",
        "style = '''\n",
        "정중하고 상냥한 톤의 문의로 변경.\n",
        "비속어와 은어는 생략하거나 순화한 표현으로 바꿀 것\n",
        "'''\n",
        "\n",
        "#템플릿을 정의\n",
        "prompt_template = '''\n",
        "주어진 {text}를 {style} 대로 변환해줘.\n",
        "text : {text}\n",
        "'''\n",
        "\n",
        "#만들어진 템플릿에 '구멍을 뚫어줘'\n",
        "template_message = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "#뚫린 포맷에 진짜 전달하고 싶은 내용 customer_email, style을 넣음\n",
        "template = template_message.format_messages(\n",
        "    style=style,\n",
        "    text = customer_email\n",
        ")\n",
        "\n",
        "response = chat(template)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWsbIFDHDS2v",
        "outputId": "7289683d-fde0-42be-b971-19d004593fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문의드립니다.\n",
            "\n",
            "어제 구매한 모니터가 켜지지 않습니다. 이것이 정상적인 상황인가요?\n",
            "반품을 원했으나 고객센터에 전화를 해도 연결이 되지 않네요.\n",
            "조속한 해결책을 부탁드립니다.\n",
            "감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_message.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7MzxreJGuTa",
        "outputId": "85ae48ae-5251-4e55-bc62-17bb3b6d28a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], template='\\n주어진 {text}를 {style} 대로 변환해줘.\\ntext : {text}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. (아웃풋) 파서   \n",
        "\n",
        "- AI가 해준 답변을 정해진 형태로 변경"
      ],
      "metadata": {
        "id": "PlRYtT-KHzkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pDOemdEbGzKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"gift\": True,\n",
        "  \"delivery_days\": 2,\n",
        "  \"price_value\": \"pretty amazing, worth it\"\n",
        "}"
      ],
      "metadata": {
        "id": "V_OJb5jXIHGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NJAGXDGoIoxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "print(prompt_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av6E1fFTJGNF",
        "outputId": "040e580f-4a04-40f7-befc-3703da8216cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = prompt_template.format_messages(text=customer_review)\n",
        "\n",
        "#채팅방!! > chat\n",
        "chat = ChatOpenAI(model='gpt-3.5-turbo',\n",
        "                  temperature=0) #창의성 정도를 조절\n",
        "\n",
        "response = chat(message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbT_iFoWJXVu",
        "outputId": "fd470dfb-6e99-4877-a405-d942e36d7bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"gift\": true,\n",
            "    \"delivery_days\": 2,\n",
            "    \"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.gift"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "uW6MFbzzJ-wd",
        "outputId": "b878e926-473f-4f77-ce25-1ccb62a3a5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'AIMessage' object has no attribute 'gift'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-434033185.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'AIMessage' object has no attribute 'gift'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#추출할 것에 대한 정의 => '스키마'\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ],
      "metadata": {
        "id": "5Mi5pTbuM2X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#name -> 내가 추출할 답변의 '키' 이름\n",
        "#description -> 어떤 정보를 추출할까?\n",
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased\\\n",
        "                             as a gift for someone else? \\\n",
        "                             Answer True if yes,\\\n",
        "                             False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days\\\n",
        "                                      did it take for the product\\\n",
        "                                      to arrive? If this \\\n",
        "                                      information is not found,\\\n",
        "                                      output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any\\\n",
        "                                    sentences about the value or \\\n",
        "                                    price, and output them as a \\\n",
        "                                    comma separated Python list.\")\n",
        "\n",
        "response_schema = [gift_schema,\n",
        "                   delivery_days_schema,\n",
        "                   price_value_schema]"
      ],
      "metadata": {
        "id": "ckm6aEtJJ931"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#'스키마'를 활용해서 답변을 받을 구조 정의\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
        "output_parser.get_format_instructions() #내가 어떻게 스키마를 정의했는가?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "xd7mj2UjJ8-Y",
        "outputId": "2af43037-a96b-45a3-abca-706c00782592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\\n\\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\\n\\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_template_2 = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product\\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "'\\'문자가 답변에 포함되지 않아야 한다.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mRz1jYL_Ns3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. chat에 구멍뚫린 양식을 전달\n",
        "prompt = ChatPromptTemplate.from_template(review_template_2)\n",
        "\n",
        "#2. {} 구멍 뚫린 곳에 실제 데이터를 전달\n",
        "instruction = output_parser.get_format_instructions()\n",
        "\n",
        "#3. 메시지로 만듦\n",
        "message = prompt.format_messages(text = customer_review,\n",
        "                                 format_instructions=instruction)\n",
        "\n",
        "#확인차 메시지를 출력\n",
        "message[0].content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I5QNkm5dOgbb",
        "outputId": "29ff4477-cdbc-465a-b184-6166a39f3ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\n\\'\\'문자가 답변에 포함되지 않아야 한다.\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife\\'s anniversary present. I think my wife liked it so much she was speechless. So far I\\'ve been the only one using it, and I\\'ve been using it every other morning to clear the leaves on our lawn. It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\n\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\\n\\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\\n\\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\\n}\\n```\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. 채팅방에 3의 메시지를 전달하여 답변을 받는다~\n",
        "response = chat(message)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkZ7AxRBO_8K",
        "outputId": "89558a5a-6d64-481b-9367-4ed889488392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "\t\"gift\": true,\n",
            "\t\"delivery_days\": 2,\n",
            "\t\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfG-NBf6Q75h",
        "outputId": "6d0ffdf0-246e-4006-823b-1fd0f6f271cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#스트링으로 답변 받은 내용을, 미리 정의한 output_parser에게 전달해서\n",
        "#내가 요청한 포맷으로 정제 하는 과정!\n",
        "#파싱을 처리\n",
        "output = output_parser.parse(response.content)\n",
        "output['gift']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHHUFWXRO-b4",
        "outputId": "0d3212d8-8446-480a-cbe6-69d94312e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['price_value']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwpedWPRAKa",
        "outputId": "8ad27336-a9b3-431a-f600-ab013f0be0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}